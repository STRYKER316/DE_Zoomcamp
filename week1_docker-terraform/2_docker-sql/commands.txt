--> have the csv file in the same directory and run the python http server to download the csv file from local directory

python -m http.server


--> Ingest yeelow_taxi csv data by running the python script created from jupyter notebook

URL="https://de-zoomcamp-files.s3.ap-south-1.amazonaws.com/yellow_tripdata_2021-01.csv"  (S3 object URL)

python upload_yellow_taxi_data.py \
    --user=root \
    --password=root \
    --host=localhost \
    --port=5432 \
    --database_name=ny_taxi \
    --table_name=yellow_taxi_trips \
    --csv_url=${URL}


--> Build the updated dockerfile for ingesting yellow_taxi_data

docker build -it yellow_taxi_data_ingest:v001 .


--> Run the docker image for ingesting csv data

URL="https://de-zoomcamp-files.s3.ap-south-1.amazonaws.com/yellow_tripdata_2021-01.csv"  (S3 object URL)

docker run -it \
    --network=pg-network \
    yellow_taxi_data_ingest:v001 \
    --user=root \
    --password=root \
    --host=pg-database \
    --port=5432 \
    --database_name=ny_taxi \
    --table_name=yellow_taxi_trips \
    --csv_url=${URL}
